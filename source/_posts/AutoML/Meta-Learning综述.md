---
title: Meta-Learning综述
date: 2018-12-17 10:28:28
categories: Meta Learning
tags:
  - Machine Learning
  - Auto Sklearn
  - Meta Learning
katex: true
---

## Meta-Learning概述

当学习新技能时，我们很少会从零开始学起，而一般会从之前类似的任务中总结有用经验、关注最适合尝试的部分，然后基于此对新技能进行学习。获得越多的技能，学习新技能就会变得更容易，在学习的过程中也需求更少的例子以及更少的试错。

简而言之，就是我们通过任务学习如何学习。而在机器学习任务中也是如此，为一个具体任务建立一个机器学习模型时，我们通常会根据关联任务经验进行构建，并基于对机器学习技术的理解做出正确的决策。而**元学习（Meta-Learning）**就是教会机器如何学习的一类算法或者一种技术。

Meta-Learning的挑战在于以**系统的、数据驱动的方式**从以往的经验中学习。首先，需要收集能够描述前序学习任务以及前序学习模型的**元数据（Meta-Data）**，由模型训练的算法配置（包括算法超参、算法管道构成或神经网络结构）、模型评估指标（如算法准确率、训练时间等）、模型参数（如神经网络的权重等）以及算法任务本身可计量的属性（如**元特征meta-features**）。然后，需要从元数据中学习能够引导后续任务的知识。

Meta-Learning涵盖了基于其他任务所有先前经验的学习。 之前的任务越相似，我们可以利用的元数据类型就越多，定义任务相似性将是一个关键的首要挑战。根据没有免费的午餐理论，当新任务代表完全不相关的现象或随机噪声时，利用先前的经验将无效。但是，在现实世界的任务中，有很多机会可以从以前的经验中学习。

根据使用的元数据类型，从通用元数据到特定任务元数据，Meta-Learning可以分为以下几类：基于模型评估的学习方法、基于元模型（Meta-Model）的学习方法以及基于参数传递的学习方法（如迁移学习等）。

## 基于模型评估的学习方法

对于$j=1, 2, 3, \cdots, n$，记学习任务为$t_i \in T$，$T$为所有已知任务集合；对于$i=1,2,3,\cdots,m$，记学习算法$A_i$的配置$\theta_i \in \Theta$，$\Theta$表示一个离散、连续或者混合的超参特征空间；记前序任务$t_j$在超参特征$\theta_i$上的模型评估结果为$P_{i,j}=P(\theta_i, t_j) \in  P$，其中$P$为前序任务预先设定的模型评估结果集合，如准确率、交叉验证结果等；记$P_{new}$为新任务$t_{new}$在超参特征空间上的所有评估结果$P_{i, new}$的集合；则元学习器（Meta-Learner）$L$就是为新任务$t_{new}$推荐合适的超参特征$\Theta_{new}^{*}$。元学习器通常在元数据$P \bigcup  P_{new}$上进行学习，其中$P$为预先计算获得或者从元数据仓库中获得；$P_{new}$通常由元学习方法迭代获得，还可以通过其它方法计算得到的$P_{new}{'}$热启动获得。

### 与任务无关的学习方法

假设无法得到新任务$t_{new}$的任何模型评估结果，即$P_{new} = \varnothing$，仍有学习方法$f: \Theta \times T \rightarrow \{\theta_{k}^*\}, k =1\cdots K$，可以得到$t_{new}$的多组超参配置。超参配置$\theta_{k}^*$应用于任务$t_{new}$并计算其评估指标，可以得到一个最优配置或者作为进一步优化方法的热启动参数。

这些学习方法通常会产生一组排名，即一组有序超参配置$\theta_{k}^*$。通常由超参特征空间$\Theta$离散为一组候选超参配置$\theta_{i}$来完成，该候选超参配置在大量任务$t_j$上进行评估。然后，对于每个任务都可以获取到一组有序超参配置，例如按照成功率、AUC等进行排序。然而，通常希望同样好但更快的算法排名更高，并且已经提出了多种方法来平衡准确性和训练时间。之后，可以将单任务的超参配置排名结果汇总为全局排名，如计算所有任务的超参配置排名结果。当没有足够的数据来构建全局排名时，可以根据每个先前任务的最佳已知配置推荐配置子集，或返回准线性排名。

为了获取任务$t_{new}$最佳超参配置$\theta^*$，一种简单的方法是选取Top-K超参配置，从上至下以此评估$t_{new}$的每组超参配置。在预定义的K值内，达到时间边界或者找到足够精确的模型后，暂停评估。在时间受限的环境中，有实验表明：多目标排名方法可以更快地收敛到最优模型，并可作为算法比较的强大基准。另一种方法则是在特定任务$t_j$先前的所有评估上拟合一个可微函数$f_j(\theta_i)= P_{i,j}$，然后利用梯度下降法寻找每个任务的优化超参配置$\theta_j^*$。假设某个新任务$\theta_{new}$与某些前序任务$\theta_j$相似，那么$\theta_j^*$就可以作为贝叶斯优化方法的热启动参数。

### 超参空间设计

先验评估可以被用于学习更好的超参空间$\Theta^*$，这可以从根本上加速搜索最佳模型，因为该方法只需要探索配置空间中更相关的区域。 当计算资源有限时，这是至关重要的，并且被证明是AutoML系统实际比较中的重要因素。

经过基于OpenML的超过100组数据集、3类算法的25万次实验，[ANOVA](http://proceedings.mlr.press/v32/hutter14-supp.pdf)方法指出，对于一个指定的任务，越能够导致算法表现差异的超参越重要。另一种方法是首先学习最佳超参数默认设置，然后将超参数重要性定义为可以通过调整超参数而不是将其保留在该默认值来实现的性能增益。

但是，即使超参数可能会导致很多方差，它也可能有一个特定的设置，总能带来良好的性能。该理论由[Probst等于2018年](https://arxiv.org/pdf/1802.09596.pdf)，通过OpenML的38组数据集、6类算法、50万次实验进行了验证。首先，针对该算法通过大量任务训练代理模型，学习算法的所有超参数默认值；接下来，对许多配置进行采样，建议的默认配置是最小化所有任务的平均风险的配置；最后，通过观察调整它仍然可以获得多少改进，来估计每个超参数的重要性（或可调性）。

Weets等于2018年提出了一种独立于其它超参数的默认值学习方法，将所有任务中最高的K组超参出现频率的参数值定义为超参数。在此种方法中，最优默认值将依赖于元特征（如数据实例数、数据特征数等），将学习简单的基于元特征的方法。接下来，在不调整超参数（或一组超参数）的情况下调整所有其他参数，以观察到的性能损失来定义是否可以安全地保留该组超参数。该方法是使用跨越59个数据集的118,000个OpenML实验和2个算法（SVM和RF）进行评估的。

### 配置迁移

如果想要为特定任务$t_{new}$提供建议，我们需要有关$t_{new}$与先前任务$t_j$的相似程度的其他信息。一种方法是在$t_{new}$上评估一些推荐的（或可能是随机的）配置，从而产生新的模型评估结果$P_{new}$，如果发现$P_{i,new}$与$P_{i, j}$近似，基于经验证据可以认为任务$t_{new}$与$t_j$是近似的。进一步，可以基于此训练一个元学习器用以预测$t_{new}$的一组推荐超参配置$\Theta_{new}^*$。此外，每组使用的超参$\theta_{new}^*$产生的模型评估结果都可以被包含在$P_{new}$中，重复这一过程可以收集到更多的经验证据用以判断任务的相似度。

#### Relative Landmarks

任务相似性的第一个度量是考虑相对（成对）性能差异，也称为Relative Landmarks，即在任务$t_j$上超参$\theta_a$与$\theta_b$的差异$RL_{a,b,j}=P_{a,j} - P_{b,j}$，如果所有超参评估的Relative Landmarks相似，则认为任务是相似的，即如果配置在$t_j$和$t_{new}$上执行类似，则认为任务相似。Active testing方法过程如下：以全局最优超参$\theta_{best}$热启动算法，并以锦标赛的形式进行调优；在每轮调优的过程中，选择一组竞争超参$\theta_c$，它在相似任务中能够令人信服的胜过超参$\theta_{best}$；接着，基于超参$\theta_c$计算模型评估结果$P_{c, new}$，更新任务相似度并重复上述操作。该方法的局限性在于它只能考虑在许多先前任务上评估的超参配置$\theta_i$。

#### 代理模型

更灵活的配置迁移方法是为所有前序任务$t_j$建立代理模型$s(\theta_i)= P_{i,j}$，$s(\theta_i)$与$P_{i, new}$之差可以用来判定任务相似程度：如果任务$t_j$的代理模型能够准确预测任务$t_{new}$，那么$t_j$与$t_{new}$是相似的。

[Wistuba等2018年](https://www.researchgate.net/profile/Marcel_Wever/publication/326930044_ML-Plan_for_Unlimited-Length_Machine_Learning_Pipelines/links/5b6d2c36299bf14c6d97e85f/ML-Plan-for-Unlimited-Length-Machine-Learning-Pipelines.pdf)训练了一种基于高斯过程的代理模型，当加入新任务$t_{new}$时，将其与前序任务结果合并为规范化的加权和，均值$\mu$被定义为$\mu_j$（由任务$t_j$获得）的加权和。$\mu_j$的权重由Nadaraya-Watson核加权平均函数计算获得，被表示为一组Relative Landmarks向量，Epanechnikov二次核函数则用于度量任务$t_{new}$与$t_j$的Relative Landmarks向量相似度。$t_j$与$t_{new}$越相近，其权重$s_j$越大，$t_j$对代理模型的影响也就越大。

[Feurer等2018年](https://arxiv.org/pdf/1802.02219.pdf)提出合并各任务独立高斯过程，将其再次统一为一个高斯过程，其权重将由[Agnostic Bayesian Ensemble](http://proceedings.mlr.press/v32/lacoste14.pdf)方法计算得出。

元数据可以基于采集函数而不是代理模型进行迁移（[Wistuba等，2018](https://www.researchgate.net/profile/Marcel_Wever/publication/326930044_ML-Plan_for_Unlimited-Length_Machine_Learning_Pipelines/links/5b6d2c36299bf14c6d97e85f/ML-Plan-for-Unlimited-Length-Machine-Learning-Pipelines.pdf)）。代理模型通常在$P_{i,new}$上进行训练，而下一个用于评估的超参$\theta_i$则是由采集函数提供，采集函数为$P_{i,new}$的期望提升与所有前序任务的$P_{i,j}$的预计提升的加权平均。前序任务的权重可以由代理模型的准确率或者通过Relative Landmarks定义；期望提升的权重则随着重复次数的增加而不断增加。

#### 热启动多任务学习

联系前序任务的另一种方法是使用任务评估结果集$P$学习其联合分布。Perrone等2017年训练了一种任务特异的贝叶斯线性回归代理模型$s_j(\theta_i)$，并利用前馈神经网络$NN(\theta_i)$将其合并用于学习$P$联合分布，该模型能够准确预测$P_{i, new}$。代理模型是在OpenML元数据中预选训练的，用于$NN(\theta_i)$的多任务热启动优化。

### 学习曲线

训练过程本身也可以作为元数据，如数据增加导致的模型精度增长速度等。若将训练过程划分为多步，记为$s_t$，则可以将任务$t_j$在超参$\theta_i$、步骤$s_t$时的模型评估结果记为$P(\theta_i,t_j,s_t)=P_{i,j,t}$，从而构成$s_t$的时间学习曲线。学习曲线可以被用于加速超参优化过程，也可以在不同任务间进行迁移。

在新任务$t_{new}$上评估超参时，循环次数$r \lt t$时停止训练，使用学习曲线预估全量数据集下超参的表现，来决定是否继续训练，该方法能够有效提速超参查找的速度。一种方法是，假定相似的任务的学习曲线也是相似的。首先，基于学习曲线的相似性定义任务距离$dist(t_a,t_b)=f(P_{i,a,t}, P_{i,b,t})$，其中$t=1,\dots,r$。然后，找到$k$个最相似的任务$t_{1\dots k}$并基于它们的完整学习曲线预测超参在新数据集上的表现。

## 基于任务属性的学习方法

任务的元特征也是一种重要的元数据。对于任务$t_j \in T$，可以被表述为一组$k$维元特征向量$m(t_j)=(m_{j,1},\dots,m_{j,k})$，其中$m_{j,k} \in M$，$M$为所有已知元特征集合。元特征可以作为任务相似度度量，例如$m(t_i)$与$m(t_j)$的欧式距离等，以便于在最相似的任务间进行信息迁移。此外，结合先验评估集$P$可以构建元学习器$L$预测新任务$t_{new}$在超参$\theta_i$上的评估$P_{i,new}$。

### 元特征 Meta-Features

![元特征Meta-Features](https://cdn.jsdelivr.net/gh/houjunxiong/houjunxiong@images/uPic/image-20190103115920759-1593867158529.png)

### 元特征学习

我们还可以学习大量任务的元特征联合表示，而不是手动定义元特征。一种方法是构建元模型，在给定其它任务的元特征$M$及评估结果$P$的情况下，生成具有里程碑式的元特征表示$M'$，即$f:M \mapsto M'$。[Sun and Pfahringer(2013)](https://link.springer.com/content/pdf/10.1007%2Fs10994-013-5387-y.pdf)在前序任务$t_j$上评估了一系列预定义的超参$\theta_i$，并针对一对超参$\theta_a$和$\theta_b$生成了一种二进制类型的元特征$m_{j,a,b} \in M'$，用来表示超参$\theta_a$的表现是否好于超参$\theta_b$，因此$m'(t_j)=(m_{j,a,b},m_{j,a,c},m_{j,b,c},\dots)$。为了计算$m_{new,a,b}$，给定元特征$m(t_j)$，对于每个成对组合$(a,b)$学习元规则，用于预测在任务$t_j$上超参$\theta_a$的表现是否好于超参$\theta_b$。

同时，也可以完全依赖于元数据$P$来学习元特征的联合表示，如$P \times \Theta \mapsto M'$。如果任务共享相同的输入空间，例如，它们是相同分辨率的图像，则还可以使用Siamese网络来学习元特征表示。可以通过将两个不同任务的数据馈送到两个双网络，并使用预测和观察到的性能$P_{i,new}$之间的差异作为误差信号来训练元特征的联合表示。由于两个网络之间的模型参数在Siamese网络中绑定，因此两个非常相似的任务被映射到潜在元特征空间中的相同区域。这些参数可以被用于热启动贝叶斯优化和神经网络结构搜索。

### 相似任务的热启动优化

元特征是一种可以用来估计任务相似性并根据类似任务有效配置并初始化优化过程的非常自然的方法。

在特定的搜索空间中启动遗传搜索算法可以显著加速算法收敛过程。[Gomes等(2017)](http://www.cin.ufpe.br/~rbcp/papers/neurocomputing_2011-18-mar.pdf)基于17种简单及统计元特征$m(t_j)$与$m(t_{new})$的L1距离寻找最近似的$k$个前序任务$t_j$，用于推荐初始化超参配置。[Reif等(2012)](https://link.springer.com/article/10.1007/s10994-012-5286-7)提出了一种非常类似的方法，基于一种前向选择技术从15种元特征中提取出最重要的部分特征，用改进的高斯变异操作热启动一种标准遗传算法（GAlib）。大量基于元特征的Active Testing方法也在不断被尝试，但是并没有表现出比基于Relative Landmarks的方法更好的性能。

基于模型的优化方法也可以从初始有效的配置中受益匪浅。[SCoT](http://www.jmlr.org/proceedings/papers/v28/bardenet13.pdf)方法训练了单一代理排序模型$f: M \times \Theta \mapsto R$用于预测任务$t_j$上的超参$\theta_i$的排名，其中$M$包含了4种元特征（3种简单元特征和1种PCA元特征）。代理模型由所有排序训练而成，也包括新任务$t_{new}$上的排序。使用排序是因为评估结果的尺度在不同任务之间可能存在很大差异。高斯过程回归将排序转换为概率以进行贝叶斯优化，并且每个新的$P_{i,new}$用于在每个步骤之后重新训练替代模型。

[Schilling等（2015）](https://ipvs.informatik.uni-stuttgart.de/mlr/spp-wordpress/wp-content/uploads/schilling-ecml-2015.pdf)使用改进的多层感知器$s_j(\theta_i,m(t_j),b(t_j))$作为代理模型，其中$m(t_j)$为元特征、$b(t_j)$为二进制向量（为0表示元实例不来源于$t_j$，为1表示元实例来源于$t_j$）。多层感知机旨在学习每个任务的潜在表示以模拟任务相似性。 由于该模型不能代表不确定性，因此训练100个多层感知器的集合以获得预测手段并模拟方差。

在所有先前的元数据上训练单个代理模型通常不太可扩展。[Yogatama and Mann (2014) ](http://proceedings.mlr.press/v33/yogatama14.pdf)建立了一个单一的贝叶斯代理模型，但只包括$t_{new}$相似度判定的任务，其中任务相似性定义为元特征向量之间的欧几里德距离，且只包括3个简单的元特征。在该方法中，$P_{i,j}$值被标准化用以避免不同任务间尺度差异的问题。代理模型在所有实例上学习具有特定内核组合的高斯过程。

[Feurer等(2014)](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.659.9959&rep=rep1&type=pdf#page=8)提出了一种简单的、扩展性高的基于任务相似度排序的贝叶斯优化热启动方法，包括了46个元特征。d个近似任务上的t个最优配置将被用于热启动贝叶斯优化过程。该方法与之前的方法相比，需要搜索更大的超参空间，甚至包括预处理过程。这种热门启动方法能够非常有效地使用，并与集合方法相结合，在Auto-Sklearn中得到了应用。

协同过滤方法也可以被用于推荐有效超参配置。与之前的方法类似，任务$t_j$（users）提供超参配置$\theta_i$（items）上的排序（$P_{i,j}$），矩阵分解技术被应用于预测未知$P_{i,j}$及为任意任务推荐最优超参。在该方法中，最大的问题是冷启动问题。[Yang等(2018)](https://arxiv.org/pdf/1808.03233.pdf)使用D最优实验设计初始化采样出了一系列$P_{i,new}$，可以同时预测出实验环境参数及对应的性能指标，可以推荐出快而精确的热启动超参。[Misir and Sebag (2013)](https://hal.inria.fr/docs/00/92/28/40/PDF/techrep_ARS.pdf)[(2017)](https://hal.inria.fr/hal-01419874/document)基于元特征解决了冷启动问题。

### 元模型

元模型可以被用于学习任务元特征与特定配置效用间的复杂关系。给定元特征集合$M$与新任务$t_{new}$，元模型$L$可以被用于推荐最有效的超参配置$\Theta_{new}^*$。

#### 排序

元模型可以生成top-K最有效的超参配置排名，例如构建KNN模型用以预测任务是否相似、进而对相似任务的最优超参进行排序。部分元模型专门用于排序，如预测聚类树、标签排序树等。[ART Forests](https://link.springer.com/content/pdf/10.1007%2Fs10994-013-5387-y.pdf)被证明尤其有效，因为该方法有内置的元特征排序功能，甚至在少量先验任务的情况下仍然可以表现良好。[autoBagging](https://arxiv.org/pdf/1706.09367.pdf)使用基于XGBoost的排名器对Bagging工作流程进行排名，包括四种不同的Bagging超参数，基于146种元特征在140个OpenML数据集上训练。[Lorena(2018)](https://link.springer.com/article/10.1007/s10994-017-5681-1)基于KNN元模型与数据复杂度元特征推荐SVM回归任务超参。

#### 效果预测

元模型也可以基于元特征及给定任务直接预测模型精度、训练时间等模型表现，基于此可以判定某超参配置是否能够在后续优化过程中进行评估。早期的工作使用线性回归或规则回归来预测超参配置的性能，然后对超参配置进行排名。[Guerra等(2008)](https://www.researchgate.net/profile/Teresa_Ludermir/publication/221078577_Predicting_the_Performance_of_Learning_Algorithms_Using_Support_Vector_Machines_as_Meta-regressors/links/0c96053c54cd15c840000000.pdf)为每个分类算法训练了一个SVM元回归器用来预测默认配置下新任务$t_{new}$的精度。[Reif等(2014)](https://www.researchgate.net/profile/Matthias_Reif/publication/230625669_Automatic_Classifier_Selection_for_Non-Experts/links/0912f50eae015c6156000000/Automatic-Classifier-Selection-for-Non-Experts.pdf)在更多的元特征下训练了一个类似的元回归器来预测任务精度。Davis等(2018)使用基于多层感知机的元学习器预测特定算法配置下的任务精度。

除预测任务精度以外，元学习器还可以用于预测任务训练/预测时间，如基于元特征训练的SVM回归器。[Yang等(2018)](https://arxiv.org/pdf/1808.03233.pdf)仅基于实例和特征的数量，使用多项式回归来预测配置运行时间。

大多数元模型都会生成有效配置，但实际上并不会将这些配置调整为自己的任务。相反，预测可以用于热启动或引导任何其他优化技术，其允许元模型和优化技术的各种组合。

此外，可以构建预测特定任务配置性能的替代模型，而不是学习任务的元功能和配置性能之间的关系。然后，可以学习如何将任务预测结果组合到热启动或指导新任务的优化技术。虽然元特征也可以用于基于任务相似性组合每个任务预测，但最终能够更有效地收集新观察结果$P_{i,new}$，因为这些可以用每个新观察结果来细化任务相似性估计。

### 管道合成

建立完整机器学习管道时，配置选项的数量急剧增加，使得利用先前的经验变得更加重要。 可以通过在管道上施加固定结构来控制搜索空间，由一组超参数完全描述。 然后，可以在类似任务上使用最有效的管道来热启动贝叶斯优化。

其他方法为某些管道步骤提供建议，并且可以在更大的管道构建方法中使用，例如规划或演化技术。[Nguyen等(2014)](http://doc.rero.ch/record/232888/files/Kalousis_2014_Using_meta-mining.pdf)使用专注于元学习器推荐组件的波束搜索来构建新的管道，并且其本身由先前成功的管道示例训练而得。[Bilalli等(2018)](https://www.sciencedirect.com/science/article/abs/pii/S0920548916302306)建立元模型为分类算法推荐相关的数据预处理算法。与之类似，Schoenfeld等(2018)建立元模型来预测某种数据预处理算法能否有效提高某分类器的准确率或者运行时间。

[AlphaD3M(2018)](https://www.cs.columbia.edu/~idrori/AlphaD3M.pdf)使用了一种自我对决的强化学习方法，其中当前管道状态作为强化学习状态量，当前管道组件的添加、删除或者替换作为强化学习的动作。利用蒙托卡罗树搜索算法生成机器学习管道，其评估结果用来训练能够预测该管道表现的LSTM，其也可以产生下一轮动作概率分布。强化学习的状态量描述中也报告元特征，使得神经网络能够跨网络进行学习。

### 调整还是不调整？

为了减少要优化的配置参数的数量，并在时间受限的设置中节省宝贵的优化时间，是否值得通过元模型来调整指定算法，这点需要通过判定调整特定算法与额外时间投资相比有多大改进来决定。对特定学习算法的更有针对性的研究产生了预测何时需要调整SVM、什么是给定任务的SVM的良好默认超参数（包括可解释的元模型）、以及如何调整决策树等元模型。

## 基于模型的学习方法

最后一类元学习方法是基于模型本身的学习，例如模型结构及参数。对于指定的新任务$t_{new}$，给定相似任务集$t_j \in T$及其对应优化模型$l_j \in L$，需要训练一个元学习器去学习如何训练新学习器$l_{new}$，其中$l_j$被定义为一系列模型参数$W=\{w_k\},k=1,\dots,K$和超参配置$\theta_i \in \Theta$。

### 迁移学习

在迁移学习中，基于一个或者多个原始任务$t_j$，将它们作为起始点在相似的目标任务上建立模型，该模型在结构或者其他方面与原始任务模型类似。这是一个普适的想法，迁移学习的方法一般集中在核方法、参数贝叶斯模型、贝叶斯网络、聚类以及强化学习方法。神经网络是非常适合迁移学习的，因为原始神经网络的结构和模型参数可以作为目标神经网络模型良好的初始化值，产生一个预训练的模型，然后可以使用$t_{new}$上的可用训练数据进一步微调。在某些情况中，原始神经网络结构在迁移前可能需要调整。

尤其在大型图像数据集上，如ImageNets，预训练模型可以被很好地迁移到其它任务上。但是，在任务并不够相似的情况下，这种迁移的效果不佳。我们可以有目的地为元学习器提供一种归纳偏见（从许多类似的任务中学习），使其能够更快地学习新任务，而不是希望预先训练好的模型“偶然”转移到一个新任务。

### 神经网络中的元学习

[暂略]

### Few-Shot Learning

[暂略]

### 监督学习以外

[暂略]